{"cells":[{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724179203265,"execution_millis":3416,"deepnote_to_be_reexecuted":false,"cell_id":"bc3a27ef721e430f8ca0601965acbaed","deepnote_cell_type":"code"},"source":"import sys\nsys.path.append('/work/')\n\nfrom dCSFA_NMF import dCSFA_NMF\nimport umc_data_tools as umc_dt\nimport pandas as pd\nimport pickle\nimport numpy as np\n\n# how to calculate power/coherence/granger causality\nimport numpy as np\nfrom scipy.signal import welch, coherence\nimport statsmodels.api as sm\nfrom spectral_connectivity import Multitaper, Connectivity\nimport re","block_group":"d2ffbac5d279448e9107205712b6bf5a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a79667349be44152b0ecb9c3c18e967d","deepnote_cell_type":"text-cell-p"},"source":"INPUT: Pandas dataframe created by Leo that has the LFP data and label data.","block_group":"4c298209b4d34e6ab11ce3194a5db1f0"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"fc4def60c46f4ae381c39f198e0f991e","deepnote_cell_type":"text-cell-p"},"source":"OUTPUT: A dictionary of arrays with spectral power density, coherence and granger causality calculated from the LFP data.","block_group":"b312b5d18f374a8a8d146be35ff6d2f1"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724179206686,"execution_millis":3557,"deepnote_to_be_reexecuted":false,"cell_id":"5c538e21c4254f77916b918d6728aa8e","deepnote_cell_type":"code"},"source":"# import data\nEPHYS_DATA_FILE = \"rce_pilot_2_10_per_trial_spectral_sleap_spikes.pkl\"\n\nwith open(EPHYS_DATA_FILE,\"rb\") as f:\n    ephys_data = pickle.load(f)\n\n# remove duplicated/redundant columns\n# ephys_data_nodup = ephys_data.T.drop_duplicates(keep='first').T\nto_drop = []\ncolumns = ephys_data.columns\n\nfor i in range(len(columns)):\n    for j in range(i + 1, len(columns)):\n        if ephys_data.iloc[:, i].equals(ephys_data.iloc[:, j]):\n            to_drop.append(columns[j])\n\n# Drop the duplicate columns\nephys_data_nodup = ephys_data.drop(columns=to_drop)\n\n# select which columns to keep\nephys_columns = [\n    \"current_subject\",\n    \"agent\",\n    \"experiment\",\n    \"in_video_subjects\",\n    \"trial_label\",\n    'trial_mPFC_lfp_trace',\n    'trial_MD_lfp_trace',\n    'trial_LH_lfp_trace',\n    'trial_BLA_lfp_trace',\n    'trial_vHPC_lfp_trace',\n    'trial_trace_timestamps',\n    'trial_subject_thorax_velocity',\n    'trial_agent_thorax_velocity',\n]\n\n# get a subset of only the columns of interest\nephys_data_nodup_subset = ephys_data_nodup[ephys_columns]\n\n# drop rows with None in agent column\nephys_data_nodup_subset = ephys_data_nodup_subset.dropna(subset=['agent'])","block_group":"459ad6d9234d46d4bb8423fa4a4fba23","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1724179300656,"execution_millis":4201,"deepnote_to_be_reexecuted":false,"cell_id":"6cd95860d10f49bdb3fc18388dbfd664","deepnote_cell_type":"code"},"source":"cols_to_use = ['tracked_subject',\n    'box_number',\n    'sleap_name',\n    'video_name',\n    'current_subject',\n    'tone_start_frame',\n    'reward_start_frame',\n    'tone_stop_frame',\n    'condition',\n    'competition_closeness',\n    'notes',\n    'experiment',\n    'session_dir',\n    'all_subjects',\n    'tone_start_timestamp',\n    'tone_stop_timestamp',\n    'trial_label',\n    'cohort',\n    'tone_frames',\n    'box_1_port_entry_frames',\n    'box_2_port_entry_frames',\n    'session_path',\n    'recording',\n    'first_timestamp',\n    'last_timestamp',\n    'tone_timestamps',\n    'box_1_port_entry_timestamps',\n    'box_2_port_entry_timestamps',\n    'lfp_timestamps',\n    'start_frame',\n    'stop_frame',\n    'in_video_subjects',\n    'body_parts',\n    'box_top_left',\n    'box_top_right',\n    'reward_port',\n    'box_bottom_left',\n    'box_bottom_right',\n    'agent',\n    'baseline_start_timestamp',\n    'baseline_stop_timestamp',\n    'baseline_mPFC_lfp_trace',\n    'baseline_MD_lfp_trace',\n    'baseline_LH_lfp_trace',\n    'baseline_BLA_lfp_trace',\n    'baseline_vHPC_lfp_trace',\n    'baseline_trace_timestamps',\n    'trial_mPFC_lfp_trace',\n    'trial_MD_lfp_trace',\n    'trial_LH_lfp_trace',\n    'trial_BLA_lfp_trace',\n    'trial_vHPC_lfp_trace',\n    'trial_trace_timestamps',\n    'baseline_agent_locations',\n    'baseline_agent_thorax_to_reward_port',\n    'baseline_agent_thorax_velocity',\n    'baseline_subject_locations',\n    'baseline_subject_thorax_to_reward_port',\n    'baseline_subject_thorax_velocity',\n    'baseline_video_timestamps',\n    'trial_agent_locations',\n    'trial_agent_thorax_to_reward_port',\n    'trial_agent_thorax_velocity',\n    'trial_subject_locations',\n    'trial_subject_thorax_to_reward_port',\n    'trial_subject_thorax_velocity',\n    'trial_video_timestamps',\n    'baseline_spike_times',\n    'trial_spike_times',\n    'baseline_neuron_average_fr',\n    'baseline_neuron_average_timestamp',\n    'trial_neuron_average_fr',\n    'trial_neuron_average_timestamp'\n]\n\nexport_df = ephys_data_nodup[cols_to_use]\nexport_df.to_csv('cohort_2_data.csv', index=False)","block_group":"bf148ee6aa2a4c009f43a2f8f12658ac","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"abed0d72381d418fb4c843f8baeabb62","deepnote_cell_type":"text-cell-h3"},"source":"### Replication of test_data structure","block_group":"631b62452cc14149a91c744a0da054c7"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1722371609014,"execution_millis":100,"deepnote_to_be_reexecuted":true,"cell_id":"fbce197a07a04957a7034652e226479f","deepnote_cell_type":"code"},"source":"# initialize dictionary for data in same structure as expected by model\nrep_data_dict = {\n    \"X_lfp\" : None,\n    \"X_psd\" : None,\n    \"X_coh\" : None,\n    \"X_gc\" : None,\n    \"y_mouse\" : None,\n    \"y_task\" : None, # this is used for the label of the model\n    \"Freqs\" : None, # frequencies at which to calculate features\n    \"powFeatures\" : None,\n    \"cohFeatures\" : None,\n    \"gcFeatures\" : None,\n    \"areas\" : None\n}","block_group":"9725c4aba866425dbf81479cf6855e4c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"28457b7cad194713a746a6f6f480c0ab","deepnote_cell_type":"text-cell-h1"},"source":"# Calculate features from LFP data","block_group":"bb0c6981a53142d3b672766754918016"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1722371609045,"execution_millis":4939860,"deepnote_to_be_reexecuted":true,"cell_id":"7306d805a3374103867a7adf0016d554","deepnote_cell_type":"code"},"source":"# areas fo the brain under investigation\nrep_data_dict[\"areas\"] = sorted([\n    'mPFC', # medial Prefrontal Cortex\n    'MD', # Mediodorsal Thalamus\n    'LH', # Lateral Hypothalamus\n    'BLA', # Basolateral Amygdala\n    'vHPC' # ventral Hippocampus\n])\n\nTOTAL_FREQS = 56 # 56 for full analysis, 0 for all together\n# frequencies to calculate power/coherence/granger causality over\nrep_data_dict[\"Freqs\"] = np.array(range(1, TOTAL_FREQS+1))\n\n# create power feature names\npow_features = []\nfor brain_area in rep_data_dict[\"areas\"]:\n    for freq in rep_data_dict[\"Freqs\"]:\n        pow_f = brain_area + \" \" + str(freq)\n        pow_features.append(pow_f)\nrep_data_dict[\"powFeatures\"] = np.array(pow_features)\nprint(\"unique power features per frequency\")\nprint(np.sort(np.unique(np.array([i.split(' ')[0] for i in list(rep_data_dict['powFeatures'])]))))\n\n# create coherence feature names\ncoh_features = []\n\nfor brain_area_1 in rep_data_dict[\"areas\"]:\n    for brain_area_2 in rep_data_dict[\"areas\"]:\n        not_processed_before = brain_area_2 not in rep_data_dict[\"areas\"][:rep_data_dict[\"areas\"].index(brain_area_1)+1]\n        if not_processed_before:\n            for freq in rep_data_dict[\"Freqs\"]:\n                coh_f = brain_area_1 + \"-\" + brain_area_2 + \" \" + str(freq)\n                coh_features.append(coh_f)\ncoh_features = pd.Series(coh_features).drop_duplicates().tolist() # remove duplicates in coh_features\ncoh_features.sort()\nrep_data_dict[\"cohFeatures\"] = np.array(coh_features)\nprint(\"unique coherence features per frequency\")\nprint(np.sort(np.unique(np.array([i.split(' ')[0] for i in list(rep_data_dict['cohFeatures'])]))))\n\n# create granger causality feature names\ngc_features = []\nfor brain_area_1 in rep_data_dict[\"areas\"]:\n    for brain_area_2 in rep_data_dict[\"areas\"]:\n        if brain_area_1 != brain_area_2:\n            for freq in rep_data_dict[\"Freqs\"]:\n                gc_f1 = brain_area_1 + \"->\" + brain_area_2 + \" \" + str(freq)\n                gc_features.append(gc_f1)\ngc_features = pd.Series(gc_features).drop_duplicates().tolist() # remove duplicates in gc_features\nrep_data_dict[\"gcFeatures\"] = np.array(gc_features)\nprint(\"unique gc features per frequency\")\nprint(np.sort(np.unique(np.array([i.split(' ')[0] for i in list(rep_data_dict['gcFeatures'])]))))\n\n# get mouse labels\nrep_data_dict[\"y_mouse\"] = np.array(ephys_data_nodup_subset[\"current_subject\"])\n\n# get trial/task labels\nrep_data_dict[\"y_task\"] = np.array(ephys_data_nodup_subset[\"trial_label\"])\n\n# create actual data\n# LFP data\nlfp_data = []\nfor brain_area in rep_data_dict[\"areas\"]:\n    # how to reshape the data to be in thje correct format\n    lfp = ephys_data_nodup_subset['trial_'+ brain_area +'_lfp_trace'].values\n    # Ensure all arrays have length 10000\n    lfp_trimmed = [arr[:9999] for arr in lfp] # THIS NEEDS TO BE DONE BETTER\n    lfp = np.vstack(lfp_trimmed)\n    lfp_data.append(lfp)\nrep_data_dict[\"X_lfp\"] = np.array(lfp_data)\n\nprint(\"Data structure created\")\nprint(\"Calculating features\")\n\n# power data calculation\npow_data = []\nfor samp in range(len(rep_data_dict[\"X_lfp\"][0])):\n    pow_val_lst = []\n    for brain_area_num in range(len(rep_data_dict[\"areas\"])):\n        # get the power data for the current brain area and sample\n        pow_dt = rep_data_dict[\"X_lfp\"][brain_area_num][samp]\n        # Oscillatory power using Welch's method\n        fs = 1000 # Sampling frequency in Hz\n        desired_freq_resolution = 1\n        # overlap deafults to 0.5 \n        f, data_psd = welch(\n            pow_dt,\n            fs, \n            nperseg=fs//desired_freq_resolution\n        ) # nperseg=fs to have resolution of 1Hz               \n        # select the power for the desired frequency and brain region\n        for freq in rep_data_dict[\"Freqs\"]:\n            # Find the index of the closest frequency in the PSD output\n            idx = np.argmin(np.abs(f - freq))\n            pow_val_lst.append(data_psd[idx])\n    # append the power data to the list\n    pow_data.append(np.array(pow_val_lst))\nrep_data_dict[\"X_psd\"] = np.array(pow_data)\n\nprint(\"Power features calculated\")\n\n# coherence data calculation\n# get the features for each brain area\ncoh_data = []\nfor samp in range(len(rep_data_dict[\"X_lfp\"][0])):\n    coh_val_lst = []\n    for fet in rep_data_dict[\"cohFeatures\"]:\n        result = re.split(r'[ \\-]+', fet)\n        coh_features = [s for s in result if s]\n        # get the index of the sample\n        area_idx_1 = rep_data_dict[\"areas\"].index(coh_features[0])\n        area_idx_2 = rep_data_dict[\"areas\"].index(coh_features[1])\n        freq = int(coh_features[2])\n        # get data for each brain area combination\n        area_data_1 = rep_data_dict[\"X_lfp\"][area_idx_1][samp]\n        area_data_2 = rep_data_dict[\"X_lfp\"][area_idx_2][samp]\n        # Cross-area synchrony (coherence)\n        fs = 1000 # Sampling frequency in Hz\n        # overlap defaults to 0.5\n        desired_freq_resolution = 1\n        f, data_coh = coherence(\n            area_data_1, \n            area_data_2, \n            fs,\n            nperseg=fs//desired_freq_resolution\n        )\n        # Find the index of the closest frequency\n        idx = np.argmin(np.abs(f - freq))\n        coh_val_lst.append(data_coh[idx])\n    # append the coherence data to the list\n    coh_data.append(np.array(coh_val_lst))\nrep_data_dict[\"X_coh\"] = np.array(coh_data)\n\nprint(\"Coherence features calculated\")\n\n# create granger casuality feature names\n# Parameters for Multitaper\ntime_halfbandwidth_product = 2  # Reasonable trade-off between time and frequency resolution\ntime_window_duration = None  # Defaults to the entire length of the signal\ntime_window_step = None  # Irrelevant when time_window_duration is None\nsampling_frequency = 1000  # The signals were sampled at 1000 Hz\ngc_data = []\nfor samp in range(len(rep_data_dict[\"X_lfp\"][0])):\n    gc_features = {}\n    brain_area_combo_lst = []\n    for brain_area_1 in rep_data_dict[\"areas\"]:\n        for brain_area_2 in rep_data_dict[\"areas\"]:\n            brain_area_combo_12 = brain_area_1 + \" -> \" + brain_area_2\n            brain_area_combo_21 = brain_area_2 + \" -> \" + brain_area_1\n            # check to make sure unecessary combinations are not computed\n            different_areas = brain_area_1 != brain_area_2\n            combo_12_not_in_list = brain_area_combo_12 not in brain_area_combo_lst\n            combo_21_not_in_list = brain_area_combo_21 not in brain_area_combo_lst\n            if different_areas and combo_12_not_in_list and combo_21_not_in_list:\n                # add brain area combination to list\n                brain_area_combo_lst.append(brain_area_combo_12)\n                brain_area_combo_lst.append(brain_area_combo_21)\n                # get the index of the sample\n                area_idx_1 = rep_data_dict[\"areas\"].index(brain_area_1)\n                area_idx_2 = rep_data_dict[\"areas\"].index(brain_area_2)\n                # get data for each brain area combination\n                array1 = rep_data_dict[\"X_lfp\"][area_idx_1][samp]\n                array2 = rep_data_dict[\"X_lfp\"][area_idx_2][samp]\n                # Combine signals into a time series\n                time_series = np.stack((array1, array2), axis=-1)\n                multitaper = Multitaper(\n                time_series=time_series,\n                sampling_frequency=sampling_frequency,\n                time_halfbandwidth_product=time_halfbandwidth_product,\n                time_window_duration=time_window_duration,\n                time_window_step=time_window_step\n                )\n                # Compute the Fourier coefficients\n                fourier_coefficients = multitaper.fft()\n                # Initialize the Connectivity analysis\n                connectivity = Connectivity(\n                    fourier_coefficients=fourier_coefficients,\n                    expectation_type='trials_tapers',\n                    frequencies=multitaper.frequencies,\n                    time=multitaper.time\n                )\n                # Calculate Granger causality\n                granger_result = connectivity.pairwise_spectral_granger_prediction()\n                # Extract the Granger causality from array1 to array2 and vice versa\n                gc_1_to_2 = granger_result[:, :, 0, 1]\n                gc_2_to_1 = granger_result[:, :, 1, 0]\n                for freq in rep_data_dict[\"Freqs\"]:\n                    # generate gcfeature names\n                    gc_name_1_to_2 = brain_area_1 + \"->\" + brain_area_2 + \" \" + str(freq)\n                    gc_name_2_to_1 = brain_area_2 + \"->\" + brain_area_1 + \" \" + str(freq)\n                    # Select the frequencies between 1 Hz and 56 Hz\n                    freq_indx = np.where(multitaper.frequencies.round(1) == freq)[0]\n                    # Extract the relevant frequency components\n                    sel_freq_1_to_2 = gc_1_to_2[:, freq_indx]\n                    sel_freq_2_to_1 = gc_2_to_1[:, freq_indx]\n\n                    nan_1_to_2 = sel_freq_1_to_2[0][0] == np.nan\n                    nan_2_to_1 = sel_freq_2_to_1[0][0] == np.nan\n                    nan_1_to_2f = type(sel_freq_1_to_2[0][0]) != np.float64\n                    nan_2_to_1f = type(sel_freq_2_to_1[0][0]) != np.float64\n                    if nan_1_to_2 or nan_2_to_1 or nan_1_to_2f or nan_2_to_1f:\n                        print(\"samp:\", samp, \n                        \" - area_1:\", brain_area_1, \n                        \" - area_2:\", brain_area_2, \n                        \" - freq:\", freq, \"\\n\\n\")\n\n                    gc_features[gc_name_1_to_2] = sel_freq_1_to_2[0][0]\n                    gc_features[gc_name_2_to_1] = sel_freq_2_to_1[0][0]\n    # Order the values in the dictionary to be the same as the features\n    gc_val_lst = []\n    for fet in rep_data_dict[\"gcFeatures\"]:\n        gc_val_lst.append(gc_features[fet])\n    # append the coherence data to the list\n    gc_data.append(np.array(gc_val_lst))\nrep_data_dict[\"X_gc\"] = np.array(gc_data)\n\n# replace nan values with 0 if gc could not be calculated\nrep_data_dict[\"X_gc\"] = np.nan_to_num(rep_data_dict[\"X_gc\"], nan=0.0)\n\nprint(\"Granger features calculated\")\nprint(\"---DONE---\")","block_group":"f2c989e738d241d6bdc619cca3ff96fc","execution_count":null,"outputs":[{"name":"stdout","text":"unique power features per frequency\n['BLA' 'LH' 'MD' 'mPFC' 'vHPC']\nunique coherence features per frequency\n['BLA-LH' 'BLA-MD' 'BLA-mPFC' 'BLA-vHPC' 'LH-MD' 'LH-mPFC' 'LH-vHPC'\n 'MD-mPFC' 'MD-vHPC' 'mPFC-vHPC']\nunique gc features per frequency\n['BLA->LH' 'BLA->MD' 'BLA->mPFC' 'BLA->vHPC' 'LH->BLA' 'LH->MD' 'LH->mPFC'\n 'LH->vHPC' 'MD->BLA' 'MD->LH' 'MD->mPFC' 'MD->vHPC' 'mPFC->BLA'\n 'mPFC->LH' 'mPFC->MD' 'mPFC->vHPC' 'vHPC->BLA' 'vHPC->LH' 'vHPC->MD'\n 'vHPC->mPFC']\nData structure created\nCalculating features\nPower features calculated\nCoherence features calculated\nMaximum iterations reached. 0 of 1 converged\nGranger features calculated\n---DONE---\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/043ac196-7c12-442f-83b6-5529dd200b98","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1722376548909,"execution_millis":84,"deepnote_to_be_reexecuted":true,"cell_id":"2506ddb11a9c4ebf85ff62a9808c85a0","deepnote_cell_type":"code"},"source":"# print dimensions of data\nfor i in rep_data_dict.keys():\n    try:\n        print(i,\":\", rep_data_dict[i].shape)\n    except:\n        print(i,\":\",rep_data_dict[i])","block_group":"9f8e63e9d7f64d1fa5523c56cb7ff1cf","execution_count":null,"outputs":[{"name":"stdout","text":"X_lfp : (5, 194, 9999)\nX_psd : (194, 280)\nX_coh : (194, 560)\nX_gc : (194, 1120)\ny_mouse : (194,)\ny_task : (194,)\nFreqs : (56,)\npowFeatures : (280,)\ncohFeatures : (560,)\ngcFeatures : (1120,)\nareas : ['BLA', 'LH', 'MD', 'mPFC', 'vHPC']\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/343c24f5-041d-4ee5-b608-d5a94d354cbb","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2476becb2d1141768687a895c6e12ad5","deepnote_cell_type":"text-cell-h3"},"source":"### Save data top disk","block_group":"fe03bb4f63d347a69b3fe49b141e282c"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1722376548910,"execution_millis":672,"deepnote_to_be_reexecuted":true,"cell_id":"a5075914fa224d37a23bace944f5e667","deepnote_cell_type":"code"},"source":"# Specify the file name\nfile_name = 'ephys_data_win_lose.pkl'\n\n# Open the file in write-binary mode and save the dictionary\nwith open(file_name, 'wb') as file:\n    pickle.dump(rep_data_dict, file)","block_group":"f55fadcd9f184a07ae1e5543b29e2833","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"47b09b9c264c4d028adbec12dac81b11","deepnote_cell_type":"separator"},"source":"<hr>","block_group":"df4b33bd8f25441284c28c1638ce4ba3"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d14e702a-7f9c-48a2-8d79-c67c05798ffa' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_full_width":true,"deepnote_notebook_id":"5ef011c5d5df46fbaa4e77710222d93b","deepnote_execution_queue":[]}}